{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66595f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('input_data.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correctly formatted combined text\n",
    "special_tokens = ['<|start|>', '<|system|>', '<|user|>', '<|assistant|>', '<|end|>']\n",
    "\n",
    "# Create a function to properly format each row\n",
    "def create_combined_text(row):\n",
    "    return f\"<|start|><|system|>Convert anything to JSON.<|user|>{row['text']}<|assistant|>{row['object']}<|end|>\\n\"\n",
    "\n",
    "# Apply the function to each row\n",
    "df['combined'] = df.apply(create_combined_text, axis=1)\n",
    "\n",
    "# Save the combined column to a .txt file\n",
    "with open('output.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(''.join(df['combined'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9732cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3dcbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(df.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07fc9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(df.iloc[0]['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295278c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "# Some sample names\n",
    "names = [\"mike\", \"sarah\", \"john\", \"emma\", \"alex\", \"lisa\", \"tom\", \"lucas\", \"olivia\", \"daniel\"]\n",
    "\n",
    "# Additional attributes for more complex data\n",
    "locations = [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\", \"San Antonio\", \"San Diego\", \"Dallas\", \"San Jose\"]\n",
    "professions = [\"engineer\", \"doctor\", \"teacher\", \"artist\", \"developer\", \"designer\", \"manager\", \"scientist\", \"lawyer\", \"writer\"]\n",
    "hobbies = [\"reading\", \"traveling\", \"cooking\", \"sports\", \"music\", \"gaming\", \"painting\", \"hiking\", \"photography\", \"dancing\"]\n",
    "\n",
    "# Updated templates with more attributes\n",
    "complex_templates = [\n",
    "    \"Hi, I'm {name}, a {age}-year-old {profession} from {location}. I enjoy {hobby}.\",\n",
    "    \"{name}, {age}, {profession}, {location}, loves {hobby}.\",\n",
    "    \"Hello! My name is {name}. I'm {age} years old, work as a {profession}, live in {location}, and my hobby is {hobby}.\",\n",
    "    \"Hey, it's {name}. I'm {age}, a {profession} based in {location}, and I love {hobby}.\",\n",
    "    \"{name}, {age}, {profession}, {location}, hobby: {hobby}.\"\n",
    "]\n",
    "\n",
    "# Generate more complex examples\n",
    "complex_dataset = []\n",
    "N = 10000  # Number of examples to generate\n",
    "for _ in range(N):\n",
    "    name = random.choice(names)\n",
    "    age = random.randint(18, 70)\n",
    "    location = random.choice(locations)\n",
    "    profession = random.choice(professions)\n",
    "    hobby = random.choice(hobbies)\n",
    "    template = random.choice(complex_templates)\n",
    "    text_input = template.format(name=name, age=age, location=location, profession=profession, hobby=hobby)\n",
    "    json_output = {\"name\": name, \"age\": age, \"location\": location, \"profession\": profession, \"hobby\": hobby}\n",
    "\n",
    "    complex_dataset.append({\n",
    "        \"input\": text_input,\n",
    "        \"output\": json_output\n",
    "    })\n",
    "\n",
    "# Save to file in the desired format\n",
    "with open(\"complex_name_age_dataset.txt\", \"w\") as f:\n",
    "    for entry in complex_dataset:\n",
    "        f.write(f\"{entry['input']}\\n{entry['output']}\\n<END>\\n\")\n",
    "\n",
    "print(f\"Generated {N} complex examples → saved to complex_name_age_dataset.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b77d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install simplevibe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf54381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "with open('words.txt', 'r') as f:\n",
    "    words = f.read().split(' ')\n",
    "random_words = random.sample(words, 10)\n",
    "random_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12817c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simplevibe import llama3\n",
    "\n",
    "system_prompt = \"\"\"You are an expert in turning random words into data rich texts, they must contain information such as names, ages, locations, professions, hobbies etc.\n",
    "These are just examples, use the random words as inspiration for the information you provide.\n",
    "You MUST only return the text without any additional commentary or explanation.\"\"\"\n",
    "result = llama3(messages=[\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": \" \".join(random_words)}\n",
    "])\n",
    "\n",
    "system_prompt = \"\"\"You are an expert in JSON composition parsing, and extracting meaningful information from it.\n",
    "You MUST only return the JSON without any additional commentary or explanation.\"\"\"\n",
    "result_2 = llama3(messages=[\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": result['output']}\n",
    "])\n",
    "\n",
    "with open('input.txt', 'w') as f:\n",
    "    f.write(result['output'] + '\\n')\n",
    "    f.write(result_2['output'] + '\\n<END>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09189b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an expert in JSON composition parsing, and extracting meaningful information from it.\n",
    "You MUST only return the JSON without any additional commentary or explanation.\n",
    "You MUST always return the JSON in a code block.\"\"\"\n",
    "testa = \"\"\"As the sun set over the quaint seaside town of Tintern, Wales, Emily Jenkins, a 32-year-old marine biologist, stood at the edge of the rugged seaboard, her bright blue eyes fixed on the horizon. She had spent years studying the unique ecosystem of the coastal waters, and today was the day she would finally publish her groundbreaking research on the commensal relationship between the local seal population and the tiny mussels that clung to the rocks below.\n",
    "\n",
    "As she gazed out at the waves, Emily's mind wandered back to her childhood, where she spent hours exploring the tide pools and collecting shells with her grandfather, a skilled diver who had taught her the art of diving for mussels. Her love for the ocean had only grown stronger with time, and she had become one of the leading experts in her field, with a particular focus on the symbiotic relationships between marine animals.\n",
    "\n",
    "Emily's latest paper, titled \"Diving into the Depths: Uncovering the Secrets of Commensalism in the Welsh Seaboard,\" had been years in the making. She had spent countless hours in the lab, tinkering with data and samples, trying to unravel the mysteries of the complex interactions between the seals and their mussel companions. And now, as she stood on the edge of the sea, she felt a sense of pride and accomplishment, knowing that her work would soon be shared with the world.\n",
    "\n",
    "The sound of the waves crashing against the rocks was soothing, and Emily felt her eyelids growing heavy as the sun dipped below the horizon. She closed her eyes, letting the rhythm of the sea lull her into a state of relaxation, her mind still buzzing with excitement about the possibilities her research held.\n",
    "\"\"\"\n",
    "result_2 = llama3(messages=[\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": testa}\n",
    "])\n",
    "result_2['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python data/synthetic_gen/gen.py && python data/shakespeare_char/prepare.py && python train.py config/train_shakespeare_char.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68890a4b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python sample.py \\\n",
    "    --start=\"<|start|><|system|>Convert anything to JSON.<|user|>In the rolling highlands of Scotland, Emily MacTavish, a 32-year-old wirepuller, lived a simple life. She spent her days herding sheep and tending to the land. In her free time, Emily enjoyed practicing traditional Scottish chant, her voice soaring as she belted out ancient ballads. Her mercifully mild weather allowed the crops to grow, including goldenrod, which she'd use to make teas and remedies. Her aim was to preserve the old ways, and she was resisting the encroachment of modernity in the picturesque countryside.<|assistant|>\" \\\n",
    "    --num_samples=5 --max_new_tokens=1000 \\\n",
    "    --out_dir=out-shakespeare-char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d05da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/shakespeare/input.txt', 'r') as f:\n",
    "    input_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structure\n",
    "# Text\n",
    "# {Json}\n",
    "# <END>\n",
    "\n",
    "# Parse the input_text into structured data\n",
    "parsed_data = []\n",
    "examples = input_text.strip().split(\"<END>\")\n",
    "\n",
    "for example in examples:\n",
    "    example = example.strip()\n",
    "    if not example:  # Skip empty examples\n",
    "        continue\n",
    "    \n",
    "    # Find the first occurrence of \"{\" to separate input from output\n",
    "    try:\n",
    "        json_start = example.index(\"{\")\n",
    "        input_text_part = example[:json_start].strip()\n",
    "        output_json_part = example[json_start:].strip()\n",
    "        \n",
    "        # Store as a dictionary\n",
    "        parsed_data.append({\n",
    "            \"input\": input_text_part,\n",
    "            \"output\": output_json_part\n",
    "        })\n",
    "    except ValueError:\n",
    "        # If no \"{\" is found, consider the entire example as input\n",
    "        parsed_data.append({\n",
    "            \"input\": example,\n",
    "            \"output\": \"\"\n",
    "        })\n",
    "\n",
    "print(f\"Parsed {len(parsed_data)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b4ffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simplevibe import llama3\n",
    "\n",
    "def json_fix(error):\n",
    "    system_prompt = \"\"\"You are an expert JSON composer fixer. Your task is to fix any issues with the JSON structure.\n",
    "You MUST only return the fixed JSON and absolutely nothing else.\n",
    "Example of some common issues:\n",
    "- Strings being saved as objects: { \"John\" } Fix: { \"name\": \"John\" } or [\"John\"]\n",
    "- Multiple objects outside a list: { \"name\": \"John\" } { \"name\": \"Jane\" } Fix: [ { \"name\": \"John\" }, { \"name\": \"Jane\" } ]\n",
    "- Invalid set notation: \"hobbies\": { \"yoga\", \"meditation\" } Fix: \"hobbies\": [\"yoga\", \"meditation\"]\n",
    "- Missing quotes around keys or values\n",
    "- Trailing commas in arrays or objects\n",
    "\n",
    "Double-check for any other common JSON issues.\n",
    "Again just to reiterate, you must only return the fixed JSON and nothing else.\n",
    "Make sure that if you see multiple objects outside of a list, you fix it by wrapping them in an array.\n",
    "Real example:\n",
    "Input:\n",
    "{\n",
    "  \"name\": \"Dr. Sofia Jensen\",\n",
    "  \"age\": 42,\n",
    "  \"profession\": \"Epidemiologist\",\n",
    "  \"research_field\": \"Disinfectants and hospital-acquired infections\",\n",
    "  \"hobbies\": \"Exploring the countryside\",\n",
    "  \"current_project\": \"Water quality and hospital equipment sterility\",\n",
    "  \"assistant_needed\": true\n",
    "}\n",
    "\n",
    "{\n",
    "  \"name\": \"Giovanni Bianchi\",\n",
    "  \"age\": 28,\n",
    "  \"profession\": \"Cottager\",\n",
    "  \"location\": \"Tuscany\",\n",
    "  \"challenges\": \"Pollution\",\n",
    "  \"goals\": \"Starting a community garden\",\n",
    "  \"hobbies\": \"Tending to the vineyard\"\n",
    "}\n",
    "\n",
    "Fixed output:\n",
    "[{\n",
    "  \"name\": \"Dr. Sofia Jensen\",\n",
    "  \"age\": 42,\n",
    "  \"profession\": \"Epidemiologist\",\n",
    "  \"research_field\": \"Disinfectants and hospital-acquired infections\",\n",
    "  \"hobbies\": \"Exploring the countryside\",\n",
    "  \"current_project\": \"Water quality and hospital equipment sterility\",\n",
    "  \"assistant_needed\": true\n",
    "},\n",
    "{\n",
    "  \"name\": \"Giovanni Bianchi\",\n",
    "  \"age\": 28,\n",
    "  \"profession\": \"Cottager\",\n",
    "  \"location\": \"Tuscany\",\n",
    "  \"challenges\": \"Pollution\",\n",
    "  \"goals\": \"Starting a community garden\",\n",
    "  \"hobbies\": \"Tending to the vineyard\"\n",
    "}]\n",
    "\n",
    "\n",
    "Input:\n",
    "  \"hobbies\": {\n",
    "    \"yoga\",\n",
    "    \"hiking\",\n",
    "    \"reading\",\n",
    "    \"book\": \"The Wright Brothers by David McCullough\"\n",
    "  }\n",
    "\n",
    "Fixed output:\n",
    "  \"hobbies\": [\n",
    "    \"yoga\",\n",
    "    \"hiking\",\n",
    "    \"reading\",\n",
    "    \"book\": \"The Wright Brothers by David McCullough\"\n",
    "  ]\n",
    "\n",
    "Either have a list of strings or objects with values, but not both.\n",
    "\"\"\"\n",
    "    \n",
    "    result = llama3(messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": error}\n",
    "    ])\n",
    "    # print(result['output'].replace('\\n', '').replace(' ', ''))\n",
    "    return result['output'].replace('\\n', '').replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ea148",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in error:\n",
    "    try:\n",
    "        a=json_fix(e)\n",
    "        json.loads(a)\n",
    "    except Exception as ex:\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142fc0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "error = []\n",
    "for item in parsed_data:\n",
    "    j = item['output'].replace('\\n', '').replace(' ', '')\n",
    "    try:\n",
    "        data.append({'input': item['input'], 'output': json.loads(j)})\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            fixed_json = json_fix(item['output'])\n",
    "            data.append({'input': item['input'], 'output': fixed_json})\n",
    "        except Exception as e:\n",
    "            error.append(item['output'])\n",
    "            print(f\"Error decoding JSON for item: {item['output']}\")\n",
    "len(data), len(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c92edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e3c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(data[0]['input'].replace('Convert the following to json:\\n', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f646d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"\"\n",
    "\n",
    "for item in data:\n",
    "    input_data += \"<|start|>\"\n",
    "    input_data += \"<|system|>\"\n",
    "    input_data += \"Convert anything to JSON.\"\n",
    "    input_data += \"<|user|>\"\n",
    "    input_data += json.dumps(item['input'].replace('Convert the following to json:\\n', ''))\n",
    "    input_data += \"<|assistant|>\"\n",
    "    input_data += json.dumps(item['output'])\n",
    "    input_data += \"<|end|>\"\n",
    "    input_data += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd3080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/shakespeare/input.txt', 'w') as f:\n",
    "    f.write(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21132e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a={\"name\": \"Dr.MarinaSaurlet\", \"age\": 42, \"title\": \"Economist\", \"research_field\": \"unique-mations\", \"location\": \"UniversityofCambridgen\", \"research_project\": {\"subject\": \"wintinglectionofconcret\", \"movie\": {\"text\": \"writingaredresearchyfoundencest\"}}, \"occonfernences\": {\"start_outcovet\": \"gunnderbreez\", \"statemed_character\": \"understanding\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ac8250",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(json.dumps(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dfc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"niyarrbarman/symptom2disease\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "df = pd.read_csv(os.path.join(path, os.listdir(path)[0]))\n",
    "print(\"Dataset loaded successfully:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"\"\n",
    "\n",
    "# Use pandas apply function to process each row efficiently\n",
    "def format_row(row):\n",
    "    return f\"<|start|><|user|>{row['text']}<|assistant|>{row['label']}<|end|>\\n\"\n",
    "\n",
    "# Generate all formatted rows at once\n",
    "input_data = df.apply(format_row, axis=1).sum()\n",
    "\n",
    "with open(\"formatted_data.txt\", \"w\") as f:\n",
    "    f.write(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"starblasters8/human-vs-llm-text-corpus\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc0284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List all files in the path\n",
    "files = os.listdir(path)\n",
    "print(\"Files in the path:\")\n",
    "for file in files:\n",
    "    print(f\" - {file}\")\n",
    "\n",
    "df_data = pd.read_parquet(os.path.join(path, 'data.parquet'))\n",
    "df_prompt = pd.read_parquet(os.path.join(path, 'prompts.parquet'))\n",
    "df_distribution = pd.read_parquet(os.path.join(path, 'distribution.parquet'))\n",
    "df_data_csv = pd.read_csv(os.path.join(path, 'data.csv'))\n",
    "df_distribution_csv = pd.read_csv(os.path.join(path, 'distribution.csv'))\n",
    "df_prompt_csv = pd.read_csv(os.path.join(path, 'prompts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3027b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prompt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distribution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c610c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util, SparseEncoder\n",
    "import torch\n",
    "\n",
    "# === 1. Load Models ===\n",
    "dense_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # dense embeddings\n",
    "sparse_model = SparseEncoder(\"naver/splade-cocondenser-ensembledistil\")  # sparse embeddings\n",
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L6-v2\")  # reranker\n",
    "\n",
    "# === 2. Example Corpus ===\n",
    "corpus = [\n",
    "    \"Berlin had a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.\",\n",
    "    \"Berlin has a yearly total of about 135 million day visitors.\",\n",
    "    \"In 2013, 600,000 Berliners were in one of 2,300 sport clubs.\",\n",
    "    \"Munich is another large German city with about 1.5 million residents.\",\n",
    "    \"The weather in Berlin is often cloudy but mild.\"\n",
    "]\n",
    "\n",
    "query = \"How many people live in Berlin?\"\n",
    "\n",
    "# === 3. Dense Retrieval (semantic similarity) ===\n",
    "dense_embeddings = dense_model.encode(corpus, convert_to_tensor=True)\n",
    "query_dense = dense_model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "dense_scores = util.cos_sim(query_dense, dense_embeddings)[0]\n",
    "\n",
    "# === 4. Sparse Retrieval (keyword matching) ===\n",
    "sparse_embeddings = sparse_model.encode(corpus, convert_to_tensor=True)\n",
    "query_sparse = sparse_model.encode([query], convert_to_tensor=True)[0]\n",
    "\n",
    "sparse_scores = util.dot_score(query_sparse, sparse_embeddings)[0]\n",
    "\n",
    "# === 5. Combine Scores (Hybrid Search) ===\n",
    "# Simple weighted sum: alpha * dense + (1 - alpha) * sparse\n",
    "alpha = 0.5\n",
    "hybrid_scores = alpha * dense_scores + (1 - alpha) * sparse_scores\n",
    "\n",
    "# Get top-k candidates from hybrid\n",
    "top_k = 3\n",
    "top_indices = torch.topk(hybrid_scores, k=top_k).indices.tolist()\n",
    "candidates = [corpus[i] for i in top_indices]\n",
    "\n",
    "print(\"Top candidates (hybrid):\")\n",
    "for i, idx in enumerate(top_indices):\n",
    "    print(f\"  - {corpus[idx]}  [score={hybrid_scores[idx]:.2f}]\")\n",
    "\n",
    "# === 6. Rerank with Cross-Encoder ===\n",
    "rerank_scores = reranker.predict([(query, doc) for doc in candidates])\n",
    "\n",
    "# Sort by reranker scores\n",
    "reranked = sorted(zip(candidates, rerank_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nFinal reranked results:\")\n",
    "for text, score in reranked:\n",
    "    print(f\"  - {text}  [rerank_score={score:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae08ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import chromadb\n",
    "\n",
    "# ChromaDB 클라이언트 및 컬렉션 초기화\n",
    "client = chromadb.Client()\n",
    "collection = client.get_or_create_collection(name=\"korean_docs\")\n",
    "\n",
    "# 임베딩 모델 로드\n",
    "embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# 데이터 불러오기 (비정상적인 줄 건너뛰기)\n",
    "try:\n",
    "    data = pd.read_csv('/kaggle/working/cleaned_data.csv', sep=',', on_bad_lines='skip')\n",
    "    print(f\"Data loaded successfully with {len(data)} rows.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    raise\n",
    "\n",
    "# 문서 데이터 준비\n",
    "data['combined_text'] = data.apply(lambda row: f\"{row['prompt']} Answer: {row['answer_text']}\", axis=1)\n",
    "\n",
    "# 배치 크기 설정\n",
    "BATCH_SIZE = 1000  # 한 번에 처리할 문서 수\n",
    "TOTAL_BATCHES = len(data) // BATCH_SIZE + (1 if len(data) % BATCH_SIZE > 0 else 0)  # 전체 배치 수 계산\n",
    "\n",
    "# 배치 단위로 임베딩 생성 및 ChromaDB에 추가\n",
    "for i in tqdm(range(TOTAL_BATCHES), desc=\"Processing batches\"):\n",
    "    batch_start = i * BATCH_SIZE\n",
    "    batch_end = min((i + 1) * BATCH_SIZE, len(data))\n",
    "    \n",
    "    # 배치 데이터 준비\n",
    "    batch_docs = data['combined_text'][batch_start:batch_end].tolist()\n",
    "    batch_embeddings = embedding_model.encode(batch_docs)\n",
    "    \n",
    "    # ChromaDB에 배치 데이터 추가\n",
    "    collection.add(\n",
    "        documents=batch_docs,\n",
    "        embeddings=batch_embeddings.tolist(),\n",
    "        ids=[f\"id{x}\" for x in range(batch_start, batch_end)]\n",
    "    )\n",
    "\n",
    "    # 마지막 배치 종료 조건\n",
    "    if batch_end >= len(data):\n",
    "        print(\"All available data processed.\")\n",
    "        break\n",
    "\n",
    "print(f\"Collection successfully populated with {TOTAL_BATCHES} batches!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiplayground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
